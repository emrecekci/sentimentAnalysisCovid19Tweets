{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Cleaning Data Tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Sentiment Analysis \n",
    "!pip install neattext\n",
    "!pip install vaderSentiment\n",
    "!pip install emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import neattext.functions as nfx\n",
    "from textblob import TextBlob\n",
    "import emoji\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Word Embedding\n",
    "!pip install gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #for TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer  #For Bag of words\n",
    "from gensim.models import Word2Vec  #For Word2Vec\n",
    "from gensim.models import FastText  #For Fast Text\n",
    "\n",
    "# Scaling and Evaluation Methods\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# ML Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"vaccination_all_tweets.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_col = ['id', 'user_name', 'user_description', 'user_created',\n",
    "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
    "       'date','source', 'retweets', 'favorites',\n",
    "       'is_retweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tweet_data.drop(unnecessary_col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.loc[data.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep=\"first\",inplace=True)\n",
    "data.reset_index(drop=True , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    if (len(string)==0):\n",
    "        return ''\n",
    "    if (set(string) == set(string[0])):\n",
    "        return ''    \n",
    "    prev = None\n",
    "    letters = [l for l in string]\n",
    "    counter = 1\n",
    "    new = []\n",
    "    for l in letters:\n",
    "        if l==prev:\n",
    "            counter+=1\n",
    "        else:\n",
    "            if (counter==2):\n",
    "                new.append(prev)\n",
    "            counter=1\n",
    "            new.append(l)\n",
    "            prev = l\n",
    "    return ''.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Text: Multiple hashtags\n",
    "data['clean_tweet'] = data['text'].apply(nfx.remove_hashtags)\n",
    "\n",
    "# Cleaning Text: userhandles\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(lambda x: nfx.remove_userhandles(x))\n",
    "\n",
    "# Cleaning Text : Remove urls\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_urls)\n",
    "\n",
    "# Cleaning Text : custom remove special characters (':', ',', ';', '.', '|','-','_','^', [&amp, &yen, ....])\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(lambda x: nfx.remove_custom_pattern(x,':+|\\,+|\\;+|\\.+|\\\"+|\\|+|\\-+|\\_+|\\%+|\\^|\\*|\\&[a-zA-Z]*'))\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(lambda x: nfx.remove_custom_words(x,'\\n'))\n",
    "\n",
    "# Cleaning Text: Punctuations\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_puncts)\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_punctuations)\n",
    "\n",
    "# Cleaning Text: dates\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_dates)\n",
    "\n",
    "# Cleaning Text: Emails\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_emails)\n",
    "\n",
    "# Cleaning Text: Numbers\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_numbers)\n",
    "                                                \n",
    "                                                \n",
    "                                                \n",
    "\n",
    "# data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_special_characters)\n",
    "\n",
    "\n",
    "\n",
    "#Remove words made up of repetitive letters\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].fillna('').map(clean)\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning Text: Multiple WhiteSpaces\n",
    "\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_multiple_spaces)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.text[58])\n",
    "print(\"=====\")\n",
    "print(data.clean_tweet[58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_obj = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    \n",
    "    text = emoji.demojize(tweet, delimiters=(\"\", \"\")).replace(\"_\" , \" \")\n",
    "    \n",
    "    blob = TextBlob(text)\n",
    "    sentiment_dict = vader_obj.polarity_scores(text)\n",
    "    \n",
    "    Compound = sentiment_dict['compound']\n",
    "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    if sentiment_subjectivity >= 0.25:\n",
    "        if Compound >= 0.05:\n",
    "            sentiment_label = 'Positive'\n",
    "        elif Compound <= - 0.05:\n",
    "            sentiment_label = 'Negative'\n",
    "        else:\n",
    "            sentiment_label = 'Neutral'\n",
    "    else: \n",
    "        sentiment_label = 'Objective'\n",
    "        \n",
    "\n",
    "    return sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = data['clean_tweet'][17]\n",
    "ex1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['clean_tweet'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data.sentiment != \"Objective\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data.drop([\"text\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.reset_index(drop=True , inplace = True)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop-Word Removal, Lower Casing, Stemming, Tokenization.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "tags = \"[^A-Za-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['monday','tuesday','wednesday','thursday','friday','saturday','sunday']\n",
    "months=['january','february','march', 'april','may','june','july','august','september','october','november','december']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['monday','tuesday','wednesday','thursday','friday','saturday','sunday']\n",
    "months=['january','february','march', 'april','may','june','july','august','september','october','november','december']\n",
    "\n",
    "\n",
    "def preprocess_text(sentence, stem = True):\n",
    "    \n",
    "    sentence = re.sub(tags,' ', str(sentence).lower()).strip()\n",
    "    text = []\n",
    "    w=\"\"\n",
    "    for word in sentence.split():\n",
    "        \n",
    "        if word not in stopwords + days + months and len(word) >= 3:\n",
    "            \n",
    "            if stem:\n",
    "                w=lemmatizer.lemmatize(word)\n",
    "                text.append(stemmer.stem(w))\n",
    "                w=\"\"\n",
    "            else:\n",
    "                text.append(word)\n",
    "                \n",
    "    return \" \".join([str(i) for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Orignal Text : {final_data.clean_tweet[7]}\")\n",
    "print(\"\\nAfter Preprocessed : \\n\")\n",
    "print(f\"Preprocessed Text : {preprocess_text(final_data.clean_tweet[7])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.clean_tweet = final_data.clean_tweet.map(preprocess_text)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "sentiment_positive_unigrams = defaultdict(int)\n",
    "for tweet in final_data.loc[final_data.sentiment == 'Positive'].clean_tweet:\n",
    "    for word in tweet.split(\" \"):\n",
    "        sentiment_positive_unigrams[word] += 1\n",
    "        \n",
    "df_sentiment_positive_unigrams = pd.DataFrame(sorted(sentiment_positive_unigrams.items(), key=lambda x: x[1])[::-1])\n",
    "\n",
    "unigrams_positive_100 = df_sentiment_positive_unigrams[:20]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentiment_negative_unigrams = defaultdict(int)\n",
    "for tweet in final_data.loc[final_data.sentiment == 'Negative'].clean_tweet:\n",
    "    for word in tweet.split(\" \"):\n",
    "        sentiment_negative_unigrams[word] += 1\n",
    "        \n",
    "df_sentiment_negative_unigrams = pd.DataFrame(sorted(sentiment_negative_unigrams.items(), key=lambda x: x[1])[::-1])\n",
    "\n",
    "unigrams_negative_100 = df_sentiment_negative_unigrams[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(18, 20//2), dpi=80)\n",
    "plt.tight_layout()\n",
    "\n",
    "sns.barplot(y=unigrams_positive_100[0], x=unigrams_positive_100[1], ax=axes[0], color='green')\n",
    "sns.barplot(y=unigrams_negative_100[0], x=unigrams_negative_100[1], ax=axes[1], color='red')\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('')\n",
    "    axes[i].tick_params(axis='x', labelsize=13)\n",
    "    axes[i].tick_params(axis='y', labelsize=13)\n",
    "\n",
    "axes[0].set_title(f'The most common words used in positive tweets {20} ', fontsize=13)\n",
    "axes[1].set_title(f'The most common words used in negative tweets {20} ', fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "final_data.sentiment = le.fit_transform(final_data.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Samples per class {}\".format(np.bincount(final_data.sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.sentiment.value_counts().plot.pie(autopct='%1.1f%%', labels=None, legend=True)\n",
    "plt.tight_layout ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag_tweet_log = final_data.loc[final_data['sentiment'] == 0]\n",
    "nag_tweet_location = nag_tweet_log['user_location'].value_counts().reset_index().rename(columns={'index':'user_location','user_location':'Count'})\n",
    "sns.barplot(y = nag_tweet_location['user_location'][1:16], x= nag_tweet_location['Count'][1:16], palette=('icefire'))\n",
    "plt.xticks(rotation=90)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(13,6)\n",
    "plt.title('Negative tweets ordered by their locations ')\n", 
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_locations = final_data['user_location'].value_counts().reset_index().rename(columns = {\n",
    "    'index':'user_location','user_location':'Count'})\n",
    "top_locations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag_tweet_location = final_data['user_location'].value_counts().reset_index().rename(columns={'index':'user_location','user_location':'Count'})\n",
    "sns.barplot(y = nag_tweet_location['user_location'][1:16], x= nag_tweet_location['Count'][1:16], palette=('icefire'))\n",
    "plt.xticks(rotation=90)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(13,6)\n",
    "plt.title('Countries ordered by the number of tweets posted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag_tweet_log = final_data.loc[final_data['sentiment'] == 2]\n",
    "nag_tweet_location = nag_tweet_log['user_location'].value_counts().reset_index().rename(columns={'index':'user_location','user_location':'Count'})\n",
    "sns.barplot(y = nag_tweet_location['user_location'][1:16], x= nag_tweet_location['Count'][1:16], palette=('icefire'))\n",
    "plt.xticks(rotation=90)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(13,6)\n",
    "plt.title('Positive tweets ordered by their locations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_lococations = final_data[final_data['user_location'].isin(final_data['user_location'].value_counts()[1:16].index)]\n",
    "# Now Ploting\n",
    "pd.crosstab(tweet_lococations.user_location, tweet_lococations.sentiment).plot.barh(stacked=True,width=1, color=sns.color_palette(\"icefire\", 9))\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(15,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #for TF-IDF\n",
    "from gensim.models import Word2Vec  #For Word2Vec\n",
    "from gensim.models import FastText  #For Fast Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_data.clean_tweet, final_data.sentiment, random_state=42, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Samples per class in train {}\".format(np.bincount(y_train)))\n",
    "print(\"Samples per class in test {}\".format(np.bincount(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df = pd.DataFrame(X_train.toarray(), columns = vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Svm Operations  */ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, prediction), precision_score(y_test, prediction, average='macro'), recall_score(y_test, prediction, average='macro'), f1_score(y_test, prediction, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cm_display.plot()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Kernal Linear */ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc= svm.SVC(kernel='linear', C=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=linear_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred_test), precision_score(y_test, y_pred_test, average='macro'), recall_score(y_test, y_pred_test, average='macro'), f1_score(y_test, y_pred_test, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*/ Kernal Poly */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svc=SVC(kernel='poly', C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_poly=poly_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred_poly), precision_score(y_test, y_pred_poly, average='macro'), recall_score(y_test, y_pred_poly, average='macro'), f1_score(y_test, y_pred_poly, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_poly)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*/ MultiNomial Logistic Regression */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial',max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, mlr_predict), precision_score(y_test, mlr_predict, average='macro'), recall_score(y_test, mlr_predict, average='macro'), f1_score(y_test, mlr_predict, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, mlr_predict)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*/DecisionTreeClassifier /*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict = dt.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, dt_predict), precision_score(y_test, dt_predict, average='macro'), recall_score(y_test, dt_predict, average='macro'), f1_score(y_test, dt_predict, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, dt_predict)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Random Forest */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predict = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, rf_predict), precision_score(y_test, rf_predict, average='macro'), recall_score(y_test, rf_predict, average='macro'), f1_score(y_test, rf_predict, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, rf_predict)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Multinomial Naive Bayes */ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predict = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, nb_predict), precision_score(y_test, nb_predict, average='macro'), recall_score(y_test, nb_predict, average='macro'), f1_score(y_test, nb_predict, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, nb_predict)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['negative', 'neutural', 'positive'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
